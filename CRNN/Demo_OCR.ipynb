{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import itertools\n",
    "import glob\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import itertools\n",
    "from unicodedata import normalize\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN = \"/home/pham.huu.quang/PycharmProjects/OCR/ICDAR/crop_linetext/b-mod_lines/train.easy\"\n",
    "PATH_VALID = \"/home/pham.huu.quang/PycharmProjects/OCR/ICDAR/crop_linetext/b-mod_lines/valid.easy\"\n",
    "PATH_TEST = \"/home/pham.huu.quang/PycharmProjects/OCR/ICDAR/crop_linetext/b-mod_lines/test.easy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/pham.huu.quang/PycharmProjects/OCR/ICDAR/crop_linetext/b-mod_lines/train.easy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ef0d28bf0056>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mcharacter_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-ef0d28bf0056>\u001b[0m in \u001b[0;36mget_labels\u001b[0;34m(path_data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATH_TRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_r\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_r\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcharacter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/pham.huu.quang/PycharmProjects/OCR/ICDAR/crop_linetext/b-mod_lines/train.easy'"
     ]
    }
   ],
   "source": [
    "def get_labels(path_data=PATH_TRAIN):\n",
    "    with open(path_data, \"r\") as f_r:\n",
    "        lines = f_r.readlines()\n",
    "\n",
    "    character = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        line = normalize(\"NFC\", line)\n",
    "        line = line.split(\" \", 1)[1]\n",
    "        line = re.sub(\"\\s+\", \"\", line)\n",
    "        character.extend(line)\n",
    "\n",
    "    character = list(set(character))\n",
    "    character = sorted(character)\n",
    "    character = \"\".join(character)\n",
    "    \n",
    "    character = \" \" + character\n",
    "    \n",
    "    return character\n",
    "\n",
    "\n",
    "character_list = get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(character_list) = ' !\"#$%\\'()*+,-./0123456789:;=?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz{|}~§©°é'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_labels(text):\n",
    "    text = normalize(\"NFC\", text)\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    return list(map(lambda x: character_list.index(x), text))\n",
    "\n",
    "\n",
    "def labels_to_text(label):\n",
    "    return ''.join(list(map(lambda x: character_list[x] if x < len(character_list) else \"\", label)))\n",
    "\n",
    "\n",
    "def ctc_loss(args):\n",
    "    y_true, y_pred, input_length, label_length = args\n",
    "    # two first steps are often garbage\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "def decode_batch(out):\n",
    "    ret = []\n",
    "    for j in range(out.shape[0]):\n",
    "        out_best = list(np.argmax(out[j, 2:], 1))\n",
    "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
    "        outstr = labels_to_text(out_best)\n",
    "        ret.append(outstr)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_CLASSES = len(character_list) + 1\n",
    "BATCH_SIZE = 12\n",
    "IMAGE_HEIGHT = 32\n",
    "NO_CHANNEL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_SIZE_1 = 6\n",
    "FILTER_SIZE_2 = 5\n",
    "FILTER_SIZE_3 = 4\n",
    "FILTER_SIZE_4 = 3\n",
    "STRIDE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, y_func, text_img_gen, text_size, num_display_words=20):\n",
    "        super().__init__()\n",
    "        self.y_func = y_func\n",
    "        self.text_img_gen = text_img_gen\n",
    "        self.num_display_words = num_display_words\n",
    "        self.text_size = text_size\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        batch = next(self.text_img_gen.next_val(\n",
    "            self.text_img_gen.img_names_val, self.text_img_gen.texts_val))[0]\n",
    "        inputs = batch['the_inputs'][:self.num_display_words]\n",
    "        labels = batch['the_labels'][:self.num_display_words].astype(np.int32)\n",
    "        labels = [labels_to_text(label) for label in labels]\n",
    "        pred = self.y_func([inputs])[0]\n",
    "        pred_texts = decode_batch(pred)\n",
    "        for i in range(min(self.num_display_words, len(inputs))):\n",
    "            print(\"label: {} - predict: {}\".format(labels[i], pred_texts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(character_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator():\n",
    "    def __init__(self, train_image_list, val_image_list, batch_size=BATCH_SIZE):\n",
    "        self.train_image_list = shuffle(train_image_list)\n",
    "        self.val_image_list = shuffle(val_image_list)\n",
    "        self.batch_size = batch_size\n",
    "        self.current_train_index = 0\n",
    "        self.current_val_index = 0\n",
    "\n",
    "    def compute_time_step(self, image_width):\n",
    "        tmp = image_width\n",
    "        for i in range(2):\n",
    "            tmp = (tmp-1) // 2 + 1\n",
    "        tmp = (tmp + STRIDE//4 - 1) // (STRIDE // 4)\n",
    "        return tmp\n",
    "\n",
    "    def load_image(self, image_path):\n",
    "        image = cv2.imread(image_path, 0)\n",
    "        ratio = image.shape[0] / IMAGE_HEIGHT\n",
    "        image = cv2.resize(image, (int(image.shape[1]/ratio), IMAGE_HEIGHT))\n",
    "        image = image / 255.\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "        return image\n",
    "\n",
    "    def get_batch(self, partition='train'):\n",
    "        if partition == 'train':\n",
    "            temp_image_list = self.train_image_list[self.current_train_index:\n",
    "                                                    self.current_train_index+self.batch_size]\n",
    "        else:\n",
    "            temp_image_list = self.val_image_list[self.current_val_index:\n",
    "                                                  self.current_val_index+self.batch_size]\n",
    "        image_array = []\n",
    "        label_array = []\n",
    "        for ind in range(self.batch_size):\n",
    "            \n",
    "            path_img_ind = temp_image_list[ind].split(\" \", 1)[0]\n",
    "            path_img_ind = os.path.join(\"../crop_linetext/b-mod_lines/lines\", path_img_ind)\n",
    "            \n",
    "            image_array.append(self.load_image(path_img_ind))\n",
    "            \n",
    "            true_label = temp_image_list[ind].split(\" \", 1)[1].strip()\n",
    "            true_label = normalize(\"NFC\", true_label)\n",
    "            label_array.append(true_label)\n",
    "            \n",
    "        max_image_width = max([m.shape[1] for m in image_array])\n",
    "        max_label_length = max(len(m) for m in label_array)\n",
    "        input_image = np.ones(\n",
    "            (self.batch_size, IMAGE_HEIGHT, max_image_width, NO_CHANNEL))\n",
    "        input_true_label = np.ones(\n",
    "            (self.batch_size, max_label_length)) * (NO_CLASSES-1)\n",
    "        input_time_step = np.zeros((self.batch_size, 1))\n",
    "        input_label_length = np.zeros((self.batch_size, 1))\n",
    "        for ind in range(self.batch_size):\n",
    "            real_width = image_array[ind].shape[1]\n",
    "            real_label_len = len(label_array[ind])\n",
    "            tmp = text_to_labels(label_array[ind])\n",
    "            input_image[ind, :, :real_width, :] = image_array[ind]\n",
    "            input_true_label[ind, :real_label_len] = tmp\n",
    "            input_time_step[ind] = self.compute_time_step(real_width) - 2\n",
    "            input_label_length[ind] = real_label_len\n",
    "        inputs = {\n",
    "            'input_image': input_image,\n",
    "            'input_true_label': input_true_label,\n",
    "            'input_time_step': input_time_step,\n",
    "            'input_label_length': input_label_length}\n",
    "        outputs = {'ctc': np.zeros((self.batch_size))}\n",
    "        return (inputs, outputs)\n",
    "\n",
    "    def next_train(self):\n",
    "        while True:\n",
    "            tmp = self.get_batch('train')\n",
    "            self.current_train_index += self.batch_size\n",
    "            if self.current_train_index >= len(self.train_image_list) - self.batch_size:\n",
    "                self.train_image_list = shuffle(self.train_image_list)\n",
    "                self.current_train_index = 0\n",
    "            yield tmp\n",
    "\n",
    "    def next_val(self):\n",
    "        while True:\n",
    "            tmp = self.get_batch('val')\n",
    "            self.current_val_index += self.batch_size\n",
    "            if self.current_val_index >= len(self.val_image_list) - self.batch_size:\n",
    "                self.val_image_list = shuffle(self.val_image_list)\n",
    "                self.current_val_index = 0\n",
    "            yield tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292738 38425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(PATH_TRAIN, \"r\") as f_r:\n",
    "    train_image_list = f_r.readlines()\n",
    "\n",
    "with open(PATH_VALID, \"r\") as f_r:\n",
    "    val_image_list = f_r.readlines()\n",
    "\n",
    "print(len(train_image_list), len(val_image_list))\n",
    "\n",
    "data_gen = DataGenerator(train_image_list, val_image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 32, 824, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data_gen.next_train())[0][\"input_image\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38425, 292738)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_image_list), len(train_image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_layer(arr, axis=1):\n",
    "    return K.squeeze(arr, axis)\n",
    "IMAGE_HEIGHT = 50\n",
    "def model():\n",
    "    rate = 0.0025\n",
    "    input_image = Input(\n",
    "        shape=(IMAGE_HEIGHT, None, NO_CHANNEL), name='input_image')\n",
    "    input_true_label = Input(shape=(None,), name='input_true_label')\n",
    "    input_time_step = Input(shape=(1,), name='input_time_step')\n",
    "    input_label_length = Input(shape=(1,), name='input_label_length')\n",
    "\n",
    "    temp = BatchNormalization()(input_image)\n",
    "#     temp = SpatialDropout2D(rate)(temp)\n",
    "    temp = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(temp)\n",
    "    temp = BatchNormalization()(temp)\n",
    "    temp = Activation('elu')(temp)\n",
    "    temp = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same')(temp)\n",
    "\n",
    "    temp = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same')(temp)\n",
    "    temp = BatchNormalization()(temp)\n",
    "    temp = Activation('elu')(temp)\n",
    "    temp = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same')(temp)\n",
    "\n",
    "    temp_1 = Conv2D(filters=16, kernel_size=(12, FILTER_SIZE_1),\n",
    "                  strides=(1, 1), padding='same')(temp)\n",
    "    temp_1 = MaxPool2D(pool_size=(6, 1))(temp_1)\n",
    "    temp_2 = Conv2D(filters=16, kernel_size=(12, FILTER_SIZE_2),\n",
    "                  strides=(1, 1), padding='same')(temp)\n",
    "    temp_2 = MaxPool2D(pool_size=(6, 1))(temp_2)\n",
    "    temp_3 = Conv2D(filters=16, kernel_size=(12, FILTER_SIZE_3),\n",
    "                  strides=(1, 1), padding='same')(temp)\n",
    "    temp_3 = MaxPool2D(pool_size=(6, 1))(temp_3)\n",
    "    temp_4 = Conv2D(filters=16, kernel_size=(12, FILTER_SIZE_4),\n",
    "                  strides=(1, 1), padding='same')(temp)\n",
    "    temp_4 = MaxPool2D(pool_size=(6, 1))(temp_4)\n",
    "    temp = concatenate([temp_1, temp_2, temp_3, temp_4], axis=-1)\n",
    "    \n",
    "    temp = Reshape([1,-1,16*2])(temp)\n",
    "    \n",
    "    temp = BatchNormalization()(temp)\n",
    "    temp = Activation('elu')(temp)\n",
    "    temp = Lambda(squeeze_layer)(temp)\n",
    "\n",
    "    gru_1 = GRU(units=64, return_sequences=True)(temp)\n",
    "    gru_1 = BatchNormalization()(gru_1)\n",
    "    gru_1 = Activation('elu')(gru_1)\n",
    "\n",
    "    dense = TimeDistributed(Dense(units=NO_CLASSES))(gru_1)\n",
    "    dense = Activation('softmax')(dense)\n",
    "    loss_out = Lambda(ctc_loss, output_shape=(1,), name='ctc')(\n",
    "        [input_true_label, dense, input_time_step, input_label_length])\n",
    "    model = Model([input_image, input_true_label,\n",
    "                   input_time_step, input_label_length], loss_out)\n",
    "    print (model.summary())\n",
    "    y_func = K.function([input_image], [dense])\n",
    "    return model, y_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4249: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4229: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        (None, 50, None, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 50, None, 1)  4           input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 50, None, 32) 320         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 50, None, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 50, None, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, None, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 25, None, 32) 9248        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 25, None, 32) 128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 25, None, 32) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 13, None, 32) 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 13, None, 16) 36880       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 13, None, 16) 30736       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 13, None, 16) 24592       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 13, None, 16) 18448       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, None, 16)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 2, None, 16)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 2, None, 16)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 2, None, 16)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, None, 64)  0           max_pooling2d_3[0][0]            \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, None, 32)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1, None, 32)  128         reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1, None, 32)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 32)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, None, 64)     18624       lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, 64)     256         gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, 64)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 94)     6110        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_true_label (InputLayer)   (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, 94)     0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_time_step (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_label_length (InputLayer) (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           input_true_label[0][0]           \n",
      "                                                                 activation_5[0][0]               \n",
      "                                                                 input_time_step[0][0]            \n",
      "                                                                 input_label_length[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 145,602\n",
      "Trainable params: 145,280\n",
      "Non-trainable params: 322\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model, y_func = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model2.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.716666666666665"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "def squeeze_layer(arr, axis=1):\n",
    "    return K.squeeze(arr, axis)\n",
    "IMAGE_HEIGHT = 50\n",
    "def model():\n",
    "    rate = 0.0025\n",
    "    input_image = Input(\n",
    "        shape=(IMAGE_HEIGHT, None, NO_CHANNEL), name='input_image')\n",
    "    input_true_label = Input(shape=(None,), name='input_true_label')\n",
    "    input_time_step = Input(shape=(1,), name='input_time_step')\n",
    "    input_label_length = Input(shape=(1,), name='input_label_length')\n",
    "\n",
    "    temp = BatchNormalization()(input_image)\n",
    "    temp = SpatialDropout2D(rate)(temp)\n",
    "    temp = Conv2D(filters=32, kernel_size=(3, 3), padding='same')(temp)\n",
    "    temp = BatchNormalization()(temp)\n",
    "    temp = Activation('elu')(temp)\n",
    "    temp = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same')(temp)\n",
    "\n",
    "    temp = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same')(temp)\n",
    "    temp = BatchNormalization()(temp)\n",
    "    temp = Activation('elu')(temp)\n",
    "    temp = MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding='same')(temp)\n",
    "\n",
    "    temp_1 = Conv2D(filters=16, kernel_size=(12, FILTER_SIZE_1),\n",
    "                  strides=(1, 1), padding='same')(temp)\n",
    "    temp_1 = MaxPool2D(pool_size=(12, 1))(temp_1)\n",
    "    temp_2 = Conv2D(filters=16, kernel_size=(12, FILTER_SIZE_2),\n",
    "                  strides=(1, 1), padding='same')(temp)\n",
    "    temp_2 = MaxPool2D(pool_size=(12, 1))(temp_2)\n",
    "    temp_3 = Conv2D(filters=16, kernel_size=(12, FILTER_SIZE_3),\n",
    "                  strides=(1, 1), padding='same')(temp)\n",
    "    temp_3 = MaxPool2D(pool_size=(12, 1))(temp_3)\n",
    "    temp_4 = Conv2D(filters=16, kernel_size=(12, FILTER_SIZE_4),\n",
    "                  strides=(1, 1), padding='same')(temp)\n",
    "    temp_4 = MaxPool2D(pool_size=(12, 1))(temp_4)\n",
    "    temp = concatenate([temp_1, temp_2, temp_3, temp_4], axis=-1)\n",
    "    \n",
    "    temp = BatchNormalization()(temp)\n",
    "    temp = Activation('elu')(temp)\n",
    "    temp = Lambda(squeeze_layer)(temp)\n",
    "    \n",
    "#     e = Dense(64, activation=\"tanh\", name=\"attention1\")(temp)\n",
    "#     energies = Dense(64, activation=\"relu\",name=\"attention2\")(e)\n",
    "#     attention_weights = Activation('softmax', name=\"attention3\")(energies)\n",
    "#     temp = Dot(axes=1, name=\"attention4\")([attention_weights,\n",
    "#                            temp])\n",
    "    temp = SeqSelfAttention(attention_activation='sigmoid')(temp)\n",
    "    print(temp.shape)\n",
    "\n",
    "    gru_1 = GRU(units=64, return_sequences=True)(temp)\n",
    "    gru_1 = BatchNormalization()(gru_1)\n",
    "    gru_1 = Activation('elu')(gru_1)\n",
    "\n",
    "    dense = TimeDistributed(Dense(units=NO_CLASSES))(gru_1)\n",
    "    dense = Activation('softmax')(dense)\n",
    "    loss_out = Lambda(ctc_loss, output_shape=(1,), name='ctc')(\n",
    "        [input_true_label, dense, input_time_step, input_label_length])\n",
    "    model = Model([input_image, input_true_label,\n",
    "                   input_time_step, input_label_length], loss_out)\n",
    "    print (model.summary())\n",
    "    y_func = K.function([input_image], [dense])\n",
    "    return model, y_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 64)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        (None, 50, None, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 50, None, 1)  4           input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_2 (SpatialDro (None, 50, None, 1)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 50, None, 32) 320         spatial_dropout2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 50, None, 32) 128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 50, None, 32) 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 25, None, 32) 0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, None, 32) 9248        max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, None, 32) 128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, None, 32) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 13, None, 32) 0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 13, None, 16) 36880       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 13, None, 16) 30736       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 13, None, 16) 24592       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 13, None, 16) 18448       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 1, None, 16)  0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 1, None, 16)  0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 1, None, 16)  0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 1, None, 16)  0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1, None, 64)  0           max_pooling2d_15[0][0]           \n",
      "                                                                 max_pooling2d_16[0][0]           \n",
      "                                                                 max_pooling2d_17[0][0]           \n",
      "                                                                 max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 1, None, 64)  256         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 1, None, 64)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None, 64)     0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "seq_self_attention_1 (SeqSelfAt (None, None, 64)     4161        lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     (None, None, 64)     24768       seq_self_attention_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, 64)     256         gru_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, 64)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, None, 94)     6110        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_true_label (InputLayer)   (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, 94)     0           time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_time_step (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_label_length (InputLayer) (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           input_true_label[0][0]           \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 input_time_step[0][0]            \n",
      "                                                                 input_label_length[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 156,035\n",
      "Trainable params: 155,649\n",
      "Non-trainable params: 386\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model, y_func = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = VizCallback(y_func, data_gen.next_val(), 100)\n",
    "earlystop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/200\n",
      "    2/12197 [..............................] - ETA: 13:08:03 - loss: 605.6382"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-24-4177be79885f>\", line 12, in <module>\n",
      "    callbacks=[checkpointer, earlystop], validation_data=data_gen.next_val(), validation_steps=step_val)\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\", line 1418, in fit_generator\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\", line 217, in fit_generator\n",
      "    class_weight=class_weight)\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\", line 1217, in train_on_batch\n",
      "    outputs = self.train_function(ins)\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 2715, in __call__\n",
      "    return self._call(inputs)\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 2675, in _call\n",
      "    fetched = self._callable_fn(*array_vals)\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\", line 1439, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/inspect.py\", line 1464, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 179, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/linecache.py\", line 137, in updatecache\n",
      "    lines = fp.readlines()\n",
      "  File \"/home/pham.huu.quang/anaconda3/lib/python3.7/codecs.py\", line 319, in decode\n",
      "    def decode(self, input, final=False):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-9,\n",
    "                 decay=1e-6, amsgrad=True, clipnorm=5., clipvalue=0.5)\n",
    "MODEL_PATH = 'pre-trained2/epoch_{epoch}_{loss:.5f}_{val_loss:.5f}.h5'\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer)\n",
    "\n",
    "step_val = len(val_image_list) // BATCH_SIZE\n",
    "step_train = len(train_image_list) // BATCH_SIZE // 2\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=MODEL_PATH, save_best_only=True, verbose=1)\n",
    "# early = EarlyStopping(patience=5)\n",
    "model.fit_generator(generator=data_gen.next_train(), steps_per_epoch=step_train, epochs=200, verbose=1,\n",
    "    callbacks=[checkpointer, earlystop], validation_data=data_gen.next_val(), validation_steps=step_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import itertools\n",
    "import glob\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import itertools\n",
    "from unicodedata import normalize\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'pre-trained2/epoch_64_0.02831_0.00532.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3c9b4b11b3dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pre-trained2/epoch_64_0.02831_0.00532.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'pre-trained2/epoch_64_0.02831_0.00532.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "model = load_model('pre-trained2/epoch_64_0.02831_0.00532.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = model.inputs[0]\n",
    "output_layer = model.layers[-4].output\n",
    "new_model = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path, 0)\n",
    "    ratio = image.shape[0] / IMAGE_HEIGHT\n",
    "    image = cv2.resize(image, (int(image.shape[1]/ratio), IMAGE_HEIGHT))\n",
    "#     image = image / 255.\n",
    "#     image = np.expand_dims(image, axis=-1)\n",
    "#     image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "IMAGE_HEIGHT = 50\n",
    "character_list = ' 1453702869'\n",
    "# character_list = \" 9570128364\"\n",
    "def validate_folder(file_list, new_model):\n",
    "    import re\n",
    "    import matplotlib.pyplot as plt\n",
    "    true_ocr = 0\n",
    "#     fw = open('wrong_ocr.txt', 'w')\n",
    "#     text = ''\n",
    "    for f in tqdm(file_list):\n",
    "        true_label = f.split('/')[-1].split('_')[0]\n",
    "        true_label = re.sub('[,円月 ]', '', true_label)\n",
    "        image_ori = load_image(f)\n",
    "        image = image_ori / 255.\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        result = np.squeeze(new_model.predict(image))[2:, :]\n",
    "        result = np.argmax(result, axis=-1)\n",
    "        result = [k for k, g in itertools.groupby(result)]\n",
    "        result = labels_to_text(result)\n",
    "#         print((result))\n",
    "#         result = [str(k) for k, _ in itertools.groupby(result) if k < 10]\n",
    "#         result = ''.join(result)\n",
    "        if result == true_label:\n",
    "            true_ocr += 1\n",
    "        else:\n",
    "            shutil.move(f, f.replace('val', 'val_verify'))\n",
    "            pass\n",
    "#             tmp_dir = os.path.join('/home/phamhoanganh/Documents/ocr_ctc/data_ocr_real_verify', true_label)\n",
    "#             if not os.path.exists(tmp_dir):\n",
    "#                 os.mkdir(tmp_dir)\n",
    "# #             print (f)\n",
    "#             text += f + '\\n'\n",
    "#             text += true_label + '  /  ' + result + '\\n'\n",
    "#             text += '_' * 100 + '\\n'\n",
    "#             plt.figure()\n",
    "#             plt.imshow(image_ori, cmap='gray')\n",
    "#             plt.show()\n",
    "#             print (f[20:], ' __ '.join([result, true_label]))\n",
    "#     fw.write(text)\n",
    "#     fw.close()\n",
    "    print (true_ocr, ' / ', len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = sorted(glob.glob('/home/phamhoanganh/Documents/ocr_ctc/data_ocr/val/*'))\n",
    "validate_folder(file_list, new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13835/13859"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16056/16091"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import itertools\n",
    "import glob\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import itertools\n",
    "from unicodedata import normalize\n",
    "import keras\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4249: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/pham.huu.quang/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4229: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('/media/SUN-ASTERISK\\pham.huu.quang/618a37c1-5b71-4a6f-be41-e2b2fdb03876/PycharmProject/OCR/ICDAR/src/state-of-the-art/easy_11_0.60781_0.42893.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        (None, 50, None, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 50, None, 1)  4           input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout2d_1 (SpatialDro (None, 50, None, 1)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 50, None, 32) 320         spatial_dropout2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 50, None, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 50, None, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, None, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 25, None, 32) 9248        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 25, None, 32) 128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 25, None, 32) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 13, None, 32) 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 13, None, 32) 73760       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 13, None, 32) 61472       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 13, None, 32) 49184       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 13, None, 32) 36896       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, None, 32)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 1, None, 32)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 1, None, 32)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, None, 32)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, None, 128) 0           max_pooling2d_3[0][0]            \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1, None, 128) 512         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1, None, 128) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, None, 128)    0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, None, 256)    197376      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, 256)    1024        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, 256)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, None, 94)     24158       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_true_label (InputLayer)   (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, 94)     0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_time_step (InputLayer)    (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_label_length (InputLayer) (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           input_true_label[0][0]           \n",
      "                                                                 activation_5[0][0]               \n",
      "                                                                 input_time_step[0][0]            \n",
      "                                                                 input_label_length[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 454,210\n",
      "Trainable params: 453,312\n",
      "Non-trainable params: 898\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = model.inputs[0]\n",
    "output_layer = model.layers[-4].output\n",
    "new_model = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path, 0)\n",
    "    ratio = image.shape[0] / IMAGE_HEIGHT\n",
    "    image = cv2.resize(image, (int(image.shape[1]/ratio), IMAGE_HEIGHT))\n",
    "#     image = image / 255.\n",
    "    print(image.shape)\n",
    "#     image = np.expand_dims(image, axis=-1)\n",
    "#     image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "IMAGE_HEIGHT = 50\n",
    "# character_list = \" 9570128364\"\n",
    "\n",
    "def labels_to_text(label):\n",
    "    return ''.join(list(map(lambda x: character_list[x] if x < len(character_list) else \"\", label)))\n",
    "\n",
    "def prediction(f, new_model):\n",
    "    image_ori = load_image(f)\n",
    "    image = image_ori / 255.\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    result = np.squeeze(new_model.predict(image))[2:, :]\n",
    "    result = np.argmax(result, axis=-1)\n",
    "    result = [k for k, g in itertools.groupby(result)]\n",
    "    result = labels_to_text(result)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 692)\n",
      "96.986 ms\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "t1 = (datetime.datetime.now())\n",
    "prediction(\"/media/SUN-ASTERISK\\pham.huu.quang/618a37c1-5b71-4a6f-be41-e2b2fdb03876/PycharmProject/OCR/ICDAR/crop_linetext/b-mod_lines/lines/0a0c9f9b0bdc29a9b41e6188d666e7a8.jpg_rec_l0004.jpg\", new_model)\n",
    "t2 = (datetime.datetime.now())\n",
    "print((t2 - t1).total_seconds()*1000, \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We wovk in the category of schemes or more generally in the category of schemes'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(\"../crop_linetext/b-mod_lines/lines/b00380517346b2e8f30c7c77b0568f90.jpg_rec_l0004.jpg\", new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012199"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_file_test = glob.glob(\"/home/phamhoanganh/Documents/ocr_quang/DemoCTC/ocr/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in list_file_test:\n",
    "    true_label = file.split(\"/\")[-2]\n",
    "    try:\n",
    "        pre_label = prediction(file, new_model)\n",
    "\n",
    "        if true_label == pre_label:\n",
    "            os.remove(file)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAIN_EASY = \"../crop_linetext/b-mod_lines/train.easy\"\n",
    "PATH_VALID_EASY = \"../crop_linetext/b-mod_lines/valid.easy\"\n",
    "PATH_TEST_EASY = \"../crop_linetext/b-mod_lines/test.easy\"\n",
    "\n",
    "PATH_TRAIN_MEDIUM = \"../crop_linetext/b-mod_lines/train.medium\"\n",
    "PATH_VALID_MEDIUM = \"../crop_linetext/b-mod_lines/valid.medium\"\n",
    "PATH_TEST_MEDIUM = \"../crop_linetext/b-mod_lines/test.medium\"\n",
    "\n",
    "PATH_TRAIN_HARD = \"../crop_linetext/b-mod_lines/train.hard\"\n",
    "PATH_VALID_HARD = \"../crop_linetext/b-mod_lines/valid.hard\"\n",
    "PATH_TEST_HARD = \"../crop_linetext/b-mod_lines/test.hard\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " !\"#$%'()*+,-./0123456789:;=?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]_abcdefghijklmnopqrstuvwxyz{|}~£§©°é€\n"
     ]
    }
   ],
   "source": [
    "def get_labels(path_data=PATH_TRAIN_EASY):\n",
    "    with open(path_data, \"r\") as f_r:\n",
    "        lines = f_r.readlines()\n",
    "\n",
    "    character = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        line = normalize(\"NFC\", line)\n",
    "        line = line.split(\" \", 1)[1]\n",
    "        line = re.sub(\"\\s+\", \"\", line)\n",
    "        character.extend(line)\n",
    "\n",
    "    character = list(set(character))\n",
    "    character = sorted(character)\n",
    "    character = \"\".join(character)\n",
    "    \n",
    "    character = \" \" + character\n",
    "    \n",
    "    return character\n",
    "\n",
    "\n",
    "character_list = get_labels(PATH_TRAIN_EASY) + get_labels(PATH_TRAIN_MEDIUM) + get_labels(PATH_TRAIN_HARD)\n",
    "character_list = list(set(character_list))\n",
    "character_list = sorted(character_list)\n",
    "character_list = \"\".join(character_list)\n",
    "character_list = character_list.replace(\" \", \"\")\n",
    "character_list = \" \" + character_list\n",
    "print(character_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40447/40447 [27:19<00:00, 24.68it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "submit_result = []\n",
    "\n",
    "with open(PATH_TEST_EASY, \"r\") as f_r:\n",
    "    lines = f_r.read().strip().split(\"\\n\")\n",
    "    for line in tqdm(lines):\n",
    "        line = line.strip()\n",
    "        submit_result.append(line + \" \" + prediction(\"../crop_linetext/b-mod_lines/lines/\" + line, new_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16411/16411 [11:31<00:00, 23.73it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(PATH_TEST_MEDIUM, \"r\") as f_r:\n",
    "    lines = f_r.read().strip().split(\"\\n\")\n",
    "    for line in tqdm(lines):\n",
    "        line = line.strip()\n",
    "        submit_result.append(line + \" \" + prediction(\"../crop_linetext/b-mod_lines/lines/\" + line, new_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2707/2707 [01:43<00:00, 26.19it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(PATH_TEST_HARD, \"r\") as f_r:\n",
    "    lines = f_r.read().strip().split(\"\\n\")\n",
    "    for line in tqdm(lines):\n",
    "        line = line.strip()\n",
    "        submit_result.append(line + \" \" + prediction(\"../crop_linetext/b-mod_lines/lines/\" + line, new_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submit_result) == (40447 + 2707 + 16411)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"w\") as f_w:\n",
    "    for line in submit_result:\n",
    "        f_w.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = (\"-l eng --oem 1 --psm 7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40447/40447 [2:03:42<00:00,  6.18it/s]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "submit_result = []\n",
    "\n",
    "with open(PATH_TEST_EASY, \"r\") as f_r:\n",
    "    lines = f_r.read().strip().split(\"\\n\")\n",
    "    for line in tqdm(lines):\n",
    "        line = line.strip()\n",
    "        submit_result.append(line + \" \" + pytesseract.image_to_string(\"../crop_linetext/b-mod_lines/lines/\" + line, config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16411/16411 [52:43<00:00,  6.20it/s]  \n"
     ]
    }
   ],
   "source": [
    "with open(PATH_TEST_MEDIUM, \"r\") as f_r:\n",
    "    lines = f_r.read().strip().split(\"\\n\")\n",
    "    for line in tqdm(lines):\n",
    "        line = line.strip()\n",
    "        submit_result.append(line + \" \" + pytesseract.image_to_string(\"../crop_linetext/b-mod_lines/lines/\" + line, config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2707/2707 [07:43<00:00,  6.47it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(PATH_TEST_HARD, \"r\") as f_r:\n",
    "    lines = f_r.read().strip().split(\"\\n\")\n",
    "    for line in tqdm(lines):\n",
    "        line = line.strip()\n",
    "        submit_result.append(line + \" \" + pytesseract.image_to_string(\"../crop_linetext/b-mod_lines/lines/\" + line, config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_tesseract.txt\", \"w\") as f_w:\n",
    "    for line in submit_result:\n",
    "        f_w.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59565"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submit_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
